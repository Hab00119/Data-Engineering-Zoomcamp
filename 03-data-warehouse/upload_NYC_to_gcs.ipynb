{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "class NYCTaxiDataLoader:\n",
    "    def __init__(self, gcp_credentials_path, bucket_name, base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\"):\n",
    "        \"\"\"\n",
    "        Initialize the NYC Taxi Data Loader\n",
    "        \n",
    "        Args:\n",
    "            gcp_credentials_path (str): Path to GCP service account JSON file\n",
    "            bucket_name (str): Name of the GCS bucket\n",
    "            base_url (str): Base URL for NYC taxi data\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.bucket_name = bucket_name\n",
    "        self.credentials = service_account.Credentials.from_service_account_file(\n",
    "            gcp_credentials_path\n",
    "        )\n",
    "        self.storage_client = storage.Client(credentials=self.credentials)\n",
    "        self.bucket = self.storage_client.bucket(bucket_name)\n",
    "        \n",
    "        # Set up logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def _generate_file_url(self, year, month):\n",
    "        \"\"\"Generate the URL for a specific year and month\"\"\"\n",
    "        file_name = f\"yellow_tripdata_{year}-{month:02d}.parquet\"\n",
    "        return f\"{self.base_url}/{file_name}\", file_name\n",
    "\n",
    "    def download_file(self, year, month):\n",
    "        \"\"\"\n",
    "        Download a single month's taxi data\n",
    "        \n",
    "        Args:\n",
    "            year (int): Year of the data\n",
    "            month (int): Month of the data\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (local_path, gcs_blob_name) if successful, None if failed\n",
    "        \"\"\"\n",
    "        url, file_name = self._generate_file_url(year, month)\n",
    "        local_path = f\"/tmp/{file_name}\"\n",
    "        \n",
    "        try:\n",
    "            # Download the file\n",
    "            self.logger.info(f\"Downloading {file_name}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(local_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "            return local_path, file_name\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading {file_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def upload_to_gcs(self, local_path, blob_name):\n",
    "        \"\"\"\n",
    "        Upload a file to Google Cloud Storage\n",
    "        \n",
    "        Args:\n",
    "            local_path (str): Path to local file\n",
    "            blob_name (str): Name for the blob in GCS\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            blob = self.bucket.blob(blob_name)\n",
    "            self.logger.info(f\"Uploading {blob_name} to GCS\")\n",
    "            blob.upload_from_filename(local_path)\n",
    "            \n",
    "            # Clean up local file\n",
    "            os.remove(local_path)\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error uploading {blob_name}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def process_month(self, year, month):\n",
    "        \"\"\"Process a single month's data (download and upload)\"\"\"\n",
    "        result = self.download_file(year, month)\n",
    "        if result:\n",
    "            local_path, blob_name = result\n",
    "            return self.upload_to_gcs(local_path, blob_name)\n",
    "        return False\n",
    "\n",
    "    def process_months(self, year, start_month=1, end_month=7, max_workers=4):\n",
    "        \"\"\"\n",
    "        Process multiple months in parallel\n",
    "        \n",
    "        Args:\n",
    "            year (int): Year of the data\n",
    "            start_month (int): Starting month (default: 1)\n",
    "            end_month (int): Ending month (default: 7)\n",
    "            max_workers (int): Maximum number of parallel workers (default: 4)\n",
    "            \n",
    "        Returns:\n",
    "            list: List of successfully processed months\n",
    "        \"\"\"\n",
    "        successful_months = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Create a list of futures for each month\n",
    "            future_to_month = {\n",
    "                executor.submit(self.process_month, year, month): month\n",
    "                for month in range(start_month, end_month + 1)\n",
    "            }\n",
    "            \n",
    "            # Process results as they complete\n",
    "            for future in future_to_month:\n",
    "                month = future_to_month[future]\n",
    "                try:\n",
    "                    if future.result():\n",
    "                        successful_months.append(month)\n",
    "                        self.logger.info(f\"Successfully processed month {month}\")\n",
    "                    else:\n",
    "                        self.logger.warning(f\"Failed to process month {month}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error processing month {month}: {str(e)}\")\n",
    "        \n",
    "        return successful_months\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    credentials_path = \"path/to/your/credentials.json\"\n",
    "    bucket_name = \"your-bucket-name\"\n",
    "    year = datetime.now().year\n",
    "    \n",
    "    loader = NYCTaxiDataLoader(credentials_path, bucket_name)\n",
    "    successful_months = loader.process_months(\n",
    "        year=year,\n",
    "        start_month=1,\n",
    "        end_month=7,\n",
    "        max_workers=4\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully processed months: {successful_months}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NYCTaxiDataLoader(\n",
    "    gcp_credentials_path=\"path/to/credentials.json\",\n",
    "    bucket_name=\"your-bucket-name\"\n",
    ")\n",
    "successful_months = loader.process_months(2024, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301d1d40-2f20-4319-966b-aeccffc742df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac962f11-a273-4868-af7b-aa7cfe13bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/03 02:56:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b133a467-c4e1-445d-8340-4252ea749765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# recursively read all data under green/2021/01\n",
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/raw/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79118ce0-0797-4dee-a994-11f1259aef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2021-01-01 00:15:56|  2021-01-01 00:19:52|                 N|         1|          43|         151|              1|         1.01|        5.5|  0.5|    0.5|         0|           0|     NULL|                  0.3|         6.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:25:59|  2021-01-01 00:34:44|                 N|         1|         166|         239|              1|         2.53|         10|  0.5|    0.5|      2.81|           0|     NULL|                  0.3|       16.86|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:45:57|  2021-01-01 00:51:55|                 N|         1|          41|          42|              1|         1.12|          6|  0.5|    0.5|         1|           0|     NULL|                  0.3|         8.3|           1|        1|                   0|\n",
      "|       2| 2020-12-31 23:57:51|  2021-01-01 00:04:56|                 N|         1|         168|          75|              1|         1.99|          8|  0.5|    0.5|         0|           0|     NULL|                  0.3|         9.3|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:16:36|  2021-01-01 00:16:40|                 N|         2|         265|         265|              3|          .00|        -52|    0|   -0.5|         0|           0|     NULL|                 -0.3|       -52.8|           3|        1|                   0|\n",
      "|       2| 2021-01-01 00:16:36|  2021-01-01 00:16:40|                 N|         2|         265|         265|              3|          .00|         52|    0|    0.5|         0|           0|     NULL|                  0.3|        52.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:19:14|  2021-01-01 00:19:21|                 N|         5|         265|         265|              1|          .00|        180|    0|      0|     36.06|           0|     NULL|                  0.3|      216.36|           1|        2|                   0|\n",
      "|       2| 2021-01-01 00:26:31|  2021-01-01 00:28:50|                 N|         1|          75|          75|              6|          .45|        3.5|  0.5|    0.5|      0.96|           0|     NULL|                  0.3|        5.76|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:57:46|  2021-01-01 00:57:57|                 N|         1|         225|         225|              1|          .00|        2.5|  0.5|    0.5|         0|           0|     NULL|                  0.3|         3.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:58:32|  2021-01-01 01:32:34|                 N|         1|         225|         265|              1|        12.19|         38|  0.5|    0.5|      2.75|           0|     NULL|                  0.3|       42.05|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:31:14|  2021-01-01 00:55:07|                 N|         1|         244|         244|              2|         3.39|         18|  0.5|    0.5|         0|           0|     NULL|                  0.3|        19.3|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:08:50|  2021-01-01 00:21:56|                 N|         1|          75|         213|              1|         6.69|       19.5|  0.5|    0.5|         0|           0|     NULL|                  0.3|        20.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:35:13|  2021-01-01 00:44:44|                 N|         1|          74|         238|              1|         2.34|         10|  0.5|    0.5|         0|           0|     NULL|                  0.3|       14.05|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:39:57|  2021-01-01 00:55:25|                 N|         1|          74|          60|              1|         5.48|         18|  0.5|    0.5|         0|           0|     NULL|                  0.3|        19.3|           2|        1|                   0|\n",
      "|       1| 2021-01-01 00:51:27|  2021-01-01 00:57:20|                 N|         1|          42|          41|              2|          .90|          6|  0.5|    0.5|         0|           0|     NULL|                  0.3|         7.3|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:29:05|  2021-01-01 00:29:07|                 N|         5|          42|         264|              1|          .00|         10|    0|      0|      2.06|           0|     NULL|                  0.3|       12.36|           1|        2|                   0|\n",
      "|       2| 2021-01-01 00:32:07|  2021-01-01 00:42:54|                 N|         1|          74|         116|              1|         2.08|        9.5|  0.5|    0.5|      2.16|           0|     NULL|                  0.3|       12.96|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:49:59|  2021-01-01 01:05:01|                 N|         1|         116|         143|              1|         4.64|       16.5|  0.5|    0.5|      5.14|           0|     NULL|                  0.3|       25.69|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:07:20|  2021-01-01 00:12:01|                 N|         1|          75|          42|              1|         1.68|        6.5|  0.5|    0.5|         0|           0|     NULL|                  0.3|         7.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:25:54|  2021-01-01 00:28:20|                 N|         1|          74|          75|              1|          .68|          4|  0.5|    0.5|         0|           0|     NULL|                  0.3|         5.3|           2|        1|                   0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fcaf97-2543-43b0-b900-52d290536b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0759be61-c0b2-49e6-aa92-812f4db57fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532083eb-16dd-4f4e-9809-5fa4ad16305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_pd = pd.read_csv(\"data/raw/green/2021/01/green_tripdata_2021-01.csv.gz\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9b4c63a-9723-4216-aac6-e8c829f78c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "lpep_pickup_datetime      object\n",
       "lpep_dropoff_datetime     object\n",
       "store_and_fwd_flag        object\n",
       "RatecodeID                 int64\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "ehail_fee                float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "payment_type               int64\n",
       "trip_type                  int64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579c7641-8429-4f6a-bc82-60d8ca464f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', StringType(), True), StructField('lpep_dropoff_datetime', StringType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', LongType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_green_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0680bb5-292b-4181-9eb8-632b51e2d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType, IntegerType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fdba587-772c-4b23-aa68-b3ad206a6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_schema = StructType([StructField('VendorID', IntegerType(), True), \n",
    "            StructField('lpep_pickup_datetime', TimestampType(), True), \n",
    "            StructField('lpep_dropoff_datetime', TimestampType(), True), \n",
    "            StructField('store_and_fwd_flag', StringType(), True), \n",
    "            StructField('RatecodeID', IntegerType(), True), \n",
    "            StructField('PULocationID', IntegerType(), True), \n",
    "            StructField('DOLocationID', IntegerType(), True), \n",
    "            StructField('passenger_count', IntegerType(), True), \n",
    "            StructField('trip_distance', DoubleType(), True), \n",
    "            StructField('fare_amount', DoubleType(), True), \n",
    "            StructField('extra', DoubleType(), True), \n",
    "            StructField('mta_tax', DoubleType(), True), \n",
    "            StructField('tip_amount', DoubleType(), True), \n",
    "            StructField('tolls_amount', DoubleType(), True), \n",
    "            StructField('ehail_fee', DoubleType(), True), \n",
    "            StructField('improvement_surcharge', DoubleType(), True), \n",
    "            StructField('total_amount', DoubleType(), True), \n",
    "            StructField('payment_type', IntegerType(), True), \n",
    "            StructField('trip_type', IntegerType(), True), \n",
    "            StructField('congestion_surcharge', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c217e47-e2d1-4506-b9aa-4ef08960c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(green_schema) \\\n",
    "    .csv('data/raw/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243fb4b-53d8-46d8-9773-b747435ff01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green \\\n",
    "    .repartition(4) \\\n",
    "    .write.parquet('data/pq/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e82af151-3e20-46de-8eb6-2062e2645aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e72b60b8-dd66-4489-b661-1a0d0a9b0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_pd = pd.read_csv(\"data/raw/yellow/2021/01/yellow_tripdata_2021-01.csv.gz\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9d7f17a-dad7-4695-9483-dab9d712c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_yellow_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "678e0099-f47a-40aa-96bc-0e8fb1ff0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_schema = StructType([StructField('VendorID', IntegerType(), True), \n",
    "            StructField('tpep_pickup_datetime', TimestampType(), True), \n",
    "            StructField('tpep_dropoff_datetime', TimestampType(), True), \n",
    "            StructField('passenger_count', IntegerType(), True), \n",
    "            StructField('trip_distance', DoubleType(), True), \n",
    "            StructField('RatecodeID', IntegerType(), True), \n",
    "            StructField('store_and_fwd_flag', StringType(), True), \n",
    "            StructField('PULocationID', IntegerType(), True), \n",
    "            StructField('DOLocationID', IntegerType(), True), \n",
    "            StructField('payment_type', LongType(), True), \n",
    "            StructField('fare_amount', DoubleType(), True), \n",
    "            StructField('extra', DoubleType(), True), \n",
    "            StructField('mta_tax', DoubleType(), True), \n",
    "            StructField('tip_amount', DoubleType(), True), \n",
    "            StructField('tolls_amount', DoubleType(), True), \n",
    "            StructField('improvement_surcharge', DoubleType(), True), \n",
    "            StructField('total_amount', DoubleType(), True), \n",
    "            StructField('congestion_surcharge', DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8528f3b0-e8b0-4c2c-b18c-59012fb55674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(yellow_schema) \\\n",
    "    .csv('data/raw/yellow/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae1e3d37-cff1-4b29-b676-ade53e982025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing yellow taxi data for years: 2020, 2021\n",
      "Processing yellow taxi data for 2020/11...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/11 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/11\n",
      "Processing yellow taxi data for 2020/08...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/08 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/08\n",
      "Processing yellow taxi data for 2020/04...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/04 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/04\n",
      "Processing yellow taxi data for 2020/01...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/01 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/01\n",
      "Processing yellow taxi data for 2020/07...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/07 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/07\n",
      "Processing yellow taxi data for 2020/05...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/05 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/05\n",
      "Processing yellow taxi data for 2020/10...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/10 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/10\n",
      "Processing yellow taxi data for 2020/09...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/09 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/09\n",
      "Processing yellow taxi data for 2020/06...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/06 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/06\n",
      "Processing yellow taxi data for 2020/02...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/02 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/02\n",
      "Processing yellow taxi data for 2020/03...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/03 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/03\n",
      "Processing yellow taxi data for 2020/12...\n",
      "Writing yellow taxi data to data/pq/yellow/2020/12 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2020/12\n",
      "Processing yellow taxi data for 2021/04...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/04 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/04\n",
      "Processing yellow taxi data for 2021/01...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/01 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/01\n",
      "Processing yellow taxi data for 2021/07...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/07 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/07\n",
      "Processing yellow taxi data for 2021/05...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/05 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/05\n",
      "Processing yellow taxi data for 2021/06...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/06 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/06\n",
      "Processing yellow taxi data for 2021/02...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/02 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/02\n",
      "Processing yellow taxi data for 2021/03...\n",
      "Writing yellow taxi data to data/pq/yellow/2021/03 with 4 partitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing yellow taxi data for 2021/03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Initialize Spark session\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"NYC Taxi Data Processing\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "def process_all_data_at_once(taxi_type, yrs=None):\n",
    "    \"\"\"\n",
    "    Approach 1: Read all data at once, partition by year/month, and save\n",
    "    \n",
    "    Args:\n",
    "        taxi_type (str): 'green' or 'yellow'\n",
    "        yrs (List[str]): List of years to process (e.g., ['2020', '2021']) or None for all years\n",
    "    \"\"\"\n",
    "    # Create path pattern based on whether specific years are provided\n",
    "    if yrs is not None and len(yrs) > 0:\n",
    "        # Create a list of paths for each specified year\n",
    "        paths = [f\"data/raw/{taxi_type}/{year}/*/*/{taxi_type}_tripdata_{year}-{month}.csv.gz\" for year in yrs]\n",
    "        print(f\"Reading {taxi_type} taxi data for years: {', '.join(yrs)}...\")\n",
    "    else:\n",
    "        # Use a single path pattern to read all years\n",
    "        paths = [f\"data/raw/{taxi_type}/*/*/*/{taxi_type}_tripdata_{year}-{month}.csv.gz\"]\n",
    "        print(f\"Reading all {taxi_type} taxi data...\")\n",
    "    \n",
    "    # Read all CSV files for the specified taxi type and years\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(get_schema(taxi_type)) \\\n",
    "        .csv(paths)\n",
    "    \n",
    "    # Add year and month columns based on input_file_name\n",
    "    df = df.withColumn(\"input_file\", spark.sql.functions.input_file_name())\n",
    "    df = df.withColumn(\"year\", spark.sql.functions.regexp_extract(\"input_file\", r\"data/raw/\\w+/(\\d{4})/\\d{2}/\", 1))\n",
    "    df = df.withColumn(\"month\", spark.sql.functions.regexp_extract(\"input_file\", r\"data/raw/\\w+/\\d{4}/(\\d{2})/\", 1))\n",
    "    \n",
    "    # Write to Parquet partitioned by year and month\n",
    "    print(f\"Writing {taxi_type} taxi data to parquet with year/month partitioning...\")\n",
    "    df.write \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(f\"data/pq/{taxi_type}\")\n",
    "    \n",
    "    print(f\"Completed processing {taxi_type} taxi data\")\n",
    "\n",
    "def process_month_by_month(taxi_type, yrs=None, num_partitions=4):\n",
    "    \"\"\"\n",
    "    Approach 2: Process data month by month and repartition each month\n",
    "    \n",
    "    Args:\n",
    "        taxi_type (str): 'green' or 'yellow'\n",
    "        yrs (List[str]): List of years to process (e.g., ['2020', '2021']) or None for all years\n",
    "        num_partitions (int): Number of partitions for each month's data\n",
    "    \"\"\"\n",
    "    # Find all years and months\n",
    "    base_path = f\"data/raw/{taxi_type}\"\n",
    "    years_months = []\n",
    "    \n",
    "    # Find all year directories\n",
    "    year_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "    # Filter years if specified\n",
    "    if yrs is not None and len(yrs) > 0:\n",
    "        year_dirs = [d for d in year_dirs if d in yrs]\n",
    "        print(f\"Processing {taxi_type} taxi data for years: {', '.join(year_dirs)}\")\n",
    "    else:\n",
    "        print(f\"Processing all {taxi_type} taxi data years\")\n",
    "    \n",
    "    for year in year_dirs:\n",
    "        # Find all month directories in this year\n",
    "        month_dirs = [d for d in os.listdir(os.path.join(base_path, year)) \n",
    "                     if os.path.isdir(os.path.join(base_path, year, d))]\n",
    "        \n",
    "        for month in month_dirs:\n",
    "            years_months.append((year, month))\n",
    "    \n",
    "    # Process each year/month separately\n",
    "    for year, month in years_months:\n",
    "        print(f\"Processing {taxi_type} taxi data for {year}/{month}...\")\n",
    "        \n",
    "        # Read data for this specific year/month\n",
    "        path = f\"data/raw/{taxi_type}/{year}/{month}/{taxi_type}_tripdata_{year}-{month}.csv.gz\"\n",
    "        \n",
    "        df = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .schema(get_schema(taxi_type)) \\\n",
    "            .csv(path)\n",
    "        \n",
    "        # Repartition the dataframe\n",
    "        df = df.repartition(num_partitions)\n",
    "        \n",
    "        # Write to Parquet\n",
    "        output_path = f\"data/pq/{taxi_type}/{year}/{month}\"\n",
    "        \n",
    "        print(f\"Writing {taxi_type} taxi data to {output_path} with {num_partitions} partitions...\")\n",
    "        df.write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .parquet(output_path)\n",
    "        \n",
    "        print(f\"Completed processing {taxi_type} taxi data for {year}/{month}\")\n",
    "\n",
    "def get_schema(taxi_type):\n",
    "    \"\"\"\n",
    "    Return the schema for the specified taxi type\n",
    "    \n",
    "    Args:\n",
    "        taxi_type (str): 'green' or 'yellow'\n",
    "    \n",
    "    Returns:\n",
    "        pyspark.sql.types.StructType: Schema for the specified taxi type\n",
    "    \"\"\"\n",
    "    if taxi_type == \"green\":\n",
    "        # Return green taxi schema that we've already created\n",
    "        return green_schema\n",
    "    elif taxi_type == \"yellow\":\n",
    "        # Return yellow taxi schema that we've already created\n",
    "        return yellow_schema\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown taxi type: {taxi_type}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the taxi type to process\n",
    "    taxi_type = \"green\"\n",
    "    \n",
    "    # Specify years to process (or set to None for all years)\n",
    "    years_to_process = [\"2020\", \"2021\"]  # Or set to None to process all years\n",
    "    \n",
    "    # Choose which approach to use\n",
    "    approach = \"month_by_month\"  # or \"all_at_once\"\n",
    "    \n",
    "    if approach == \"all_at_once\":\n",
    "        process_all_data_at_once(taxi_type, yrs=years_to_process)\n",
    "    else:\n",
    "        process_month_by_month(taxi_type, yrs=years_to_process, num_partitions=4)\n",
    "    \n",
    "    # Process the other taxi type if needed\n",
    "    # taxi_type = \"yellow\"\n",
    "    # process_all_data_at_once(taxi_type, yrs=years_to_process)  # or process_month_by_month(taxi_type, yrs=years_to_process)\n",
    "    \n",
    "    # Stop Spark session\n",
    "    #spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16294b8-31e6-4761-b9f4-08792936e28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
